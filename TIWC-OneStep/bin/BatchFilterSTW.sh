#Batch filtering on test data set 1 & trainingSetforAtemporal-TemporalOneStep.arff
#---------------------------------------------------------------------------------------------------------------------------
java -classpath /usr/share/java/weka.jar weka.filters.unsupervised.attribute.StringToWordVector -b -i /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/trainingSetforAtemporal-TemporalOneStep.arff -o  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/2-3GramOneStep/ngram_trainingSetforAtemporal-TemporalOneStep_set.arff -c first -r /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/ngram_data_set1.arff -s  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/2-3GramOneStep/ngram_data_output_set1.arff -R 1,2 -O -C -T -I -N 0 -M 1 -tokenizer 'weka.core.tokenizers.NGramTokenizer -min 2 -max 3'
#Batch filtering on test data set 2 & trainingSetforAtemporal-TemporalOneStep.arff
#---------------------------------------------------------------------------------------------------------------------------
java -classpath /usr/share/java/weka.jar weka.filters.unsupervised.attribute.StringToWordVector -b -i /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/trainingSetforAtemporal-TemporalOneStep.arff -o  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/2-3GramOneStep/ngram_trainingSetforAtemporal-TemporalOneStep_set.arff -c first -r /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/ngram_data_set2.arff -s  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/2-3GramOneStep/ngram_data_output_set2.arff -R 1,2 -O -C -T -I -N 0 -M 1 -tokenizer 'weka.core.tokenizers.NGramTokenizer -min 2 -max 3'
#Batch filtering on test data set 3 & trainingSetforAtemporal-TemporalOneStep.arff
#---------------------------------------------------------------------------------------------------------------------------
java -classpath /usr/share/java/weka.jar weka.filters.unsupervised.attribute.StringToWordVector -b -i /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/trainingSetforAtemporal-TemporalOneStep.arff -o  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/2-3GramOneStep/ngram_trainingSetforAtemporal-TemporalOneStep_set.arff -c first -r /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/ngram_data_set3.arff -s  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/2-3GramOneStep/ngram_data_output_set3.arff -R 1,2 -O -C -T -I -N 0 -M 1 -tokenizer 'weka.core.tokenizers.NGramTokenizer -min 2 -max 3'
#Batch filtering on test data set 4 & trainingSetforAtemporal-TemporalOneStep.arff
#---------------------------------------------------------------------------------------------------------------------------
java -classpath /usr/share/java/weka.jar weka.filters.unsupervised.attribute.StringToWordVector -b -i /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/trainingSetforAtemporal-TemporalOneStep.arff -o  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/2-3GramOneStep/ngram_trainingSetforAtemporal-TemporalOneStep_set.arff -c first -r /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/ngram_data_set4.arff -s  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/2-3GramOneStep/ngram_data_output_set4.arff -R 1,2 -O -C -T -I -N 0 -M 1 -tokenizer 'weka.core.tokenizers.NGramTokenizer -min 2 -max 3'
#Batch filtering on test data set 5 & trainingSetforAtemporal-TemporalOneStep.arff
#---------------------------------------------------------------------------------------------------------------------------
java -classpath /usr/share/java/weka.jar weka.filters.unsupervised.attribute.StringToWordVector -b -i /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/trainingSetforAtemporal-TemporalOneStep.arff -o  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/2-3GramOneStep/ngram_trainingSetforAtemporal-TemporalOneStep_set.arff -c first -r /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/ngram_data_set5.arff -s  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/2-3GramOneStep/ngram_data_output_set5.arff -R 1,2 -O -C -T -I -N 0 -M 1 -tokenizer 'weka.core.tokenizers.NGramTokenizer -min 2 -max 3'
#Batch filtering on test data set 6 & trainingSetforAtemporal-TemporalOneStep.arff
#---------------------------------------------------------------------------------------------------------------------------
java -classpath /usr/share/java/weka.jar weka.filters.unsupervised.attribute.StringToWordVector -b -i /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/trainingSetforAtemporal-TemporalOneStep.arff -o  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/2-3GramOneStep/ngram_trainingSetforAtemporal-TemporalOneStep_set.arff -c first -r /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/ngram_data_set6.arff -s  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/2-3GramOneStep/ngram_data_output_set6.arff -R 1,2 -O -C -T -I -N 0 -M 1 -tokenizer 'weka.core.tokenizers.NGramTokenizer -min 2 -max 3'
#Batch filtering on test data set 7 & trainingSetforAtemporal-TemporalOneStep.arff
#---------------------------------------------------------------------------------------------------------------------------
java -classpath /usr/share/java/weka.jar weka.filters.unsupervised.attribute.StringToWordVector -b -i /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/trainingSetforAtemporal-TemporalOneStep.arff -o  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/2-3GramOneStep/ngram_trainingSetforAtemporal-TemporalOneStep_set.arff -c first -r /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/ngram_data_set7.arff -s  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/2-3GramOneStep/ngram_data_output_set7.arff -R 1,2 -O -C -T -I -N 0 -M 1 -tokenizer 'weka.core.tokenizers.NGramTokenizer -min 2 -max 3'
#Batch filtering on test data set 8 & trainingSetforAtemporal-TemporalOneStep.arff
#---------------------------------------------------------------------------------------------------------------------------
java -classpath /usr/share/java/weka.jar weka.filters.unsupervised.attribute.StringToWordVector -b -i /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/trainingSetforAtemporal-TemporalOneStep.arff -o  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/2-3GramOneStep/ngram_trainingSetforAtemporal-TemporalOneStep_set.arff -c first -r /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/ngram_data_set8.arff -s  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/2-3GramOneStep/ngram_data_output_set8.arff -R 1,2 -O -C -T -I -N 0 -M 1 -tokenizer 'weka.core.tokenizers.NGramTokenizer -min 2 -max 3'
#Batch filtering on test data set 9 & trainingSetforAtemporal-TemporalOneStep.arff
#---------------------------------------------------------------------------------------------------------------------------
java -classpath /usr/share/java/weka.jar weka.filters.unsupervised.attribute.StringToWordVector -b -i /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/trainingSetforAtemporal-TemporalOneStep.arff -o  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/2-3GramOneStep/ngram_trainingSetforAtemporal-TemporalOneStep_set.arff -c first -r /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/ngram_data_set9.arff -s  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/2-3GramOneStep/ngram_data_output_set9.arff -R 1,2 -O -C -T -I -N 0 -M 1 -tokenizer 'weka.core.tokenizers.NGramTokenizer -min 2 -max 3'
#Batch filtering on test data set 10 & trainingSetforAtemporal-TemporalOneStep.arff
#---------------------------------------------------------------------------------------------------------------------------
java -classpath /usr/share/java/weka.jar weka.filters.unsupervised.attribute.StringToWordVector -b -i /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/trainingSetforAtemporal-TemporalOneStep.arff -o  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TrainingData/2-3GramOneStep/ngram_trainingSetforAtemporal-TemporalOneStep_set.arff -c first -r /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/ngram_data_set10.arff -s  /home/dipawesh/workspace/Hindi_wordnet_time_tagging/TestData/DatasetInChunks/2-3GramOneStep/ngram_data_output_set10.arff -R 1,2 -O -C -T -I -N 0 -M 1 -tokenizer 'weka.core.tokenizers.NGramTokenizer -min 2 -max 3'
